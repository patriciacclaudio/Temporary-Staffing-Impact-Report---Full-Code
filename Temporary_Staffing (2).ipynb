{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from datetime import datetime, timedelta\n",
        "from pandas.tseries.offsets import DateOffset"
      ],
      "metadata": {
        "id": "sTy_EN5v6QSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Locum's Nest - Agency**\n"
      ],
      "metadata": {
        "id": "D7LpCO1K6TLs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfdSmdpd1Byc"
      },
      "outputs": [],
      "source": [
        "# Load the raw input file and load the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('Agency_RN_HCA.xlsx')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with the word \"Agency\" in every row\n",
        "df['Bank/agency'] = 'Agency'\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "-WcsBG5M2Qr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Bid ID',\n",
        "    'Professional registration number',\n",
        "    'Agency',\n",
        "    'Bid Date (submission)',\n",
        "    'Bid Time (submission)',\n",
        "    'Current bid status',\n",
        "    'Current bid status effective date',\n",
        "    'Current bid status effective time',\n",
        "    'Reason for cancellation',\n",
        "    'Reason for rejection',\n",
        "    'Staff Bank Affiliations',\n",
        "    'Listing ID',\n",
        "    'Listing Title',\n",
        "    'Listing Site',\n",
        "    'Listing Organisation',\n",
        "    'SubSpecialty',\n",
        "    'Ward Name',\n",
        "    'Job Listing Published Date',\n",
        "    'Job Listing Published Time',\n",
        "    'Application  Deadline Date',\n",
        "    'Application  Deadline Time',\n",
        "    'Direct Engagement',\n",
        "    'Start Time',\n",
        "    'End Time',\n",
        "    'Locked'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "wop-G67M5C3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'Profession',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Cost Centre',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Start Date',\n",
        "    'Total hours',\n",
        "    'Grade',\n",
        "    'Total Pay including agency fees excluding break time deduction (Â£)',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder the columns\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "1Hhk58KR5T7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Agency_RN_HCA_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "LfYcSUdk7Im3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Locum's Nest - Bank**"
      ],
      "metadata": {
        "id": "P5NWKBEJ7WnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bank A&C, Dom & Estates**"
      ],
      "metadata": {
        "id": "eR2lsAH-HzJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file containing the LN Bank data and display the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('Bank_A&C_Dom_Estates.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8ZoxEENVGQTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with the word \"Bank\" in every row\n",
        "df['Bank/agency'] = 'Bank'\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Y8C5kO7NGfKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Application ID',\n",
        "    'Professional registration number',\n",
        "    'Application Date',\n",
        "    'Application Time',\n",
        "    'Current Application Status',\n",
        "    'Current Application status effective date',\n",
        "    'Current Application status effective time',\n",
        "    'Reason for Cancellation',\n",
        "    'Reason for Rejection',\n",
        "    'Reason for Rejection Description',\n",
        "    'Applicant Staff Bank Status',\n",
        "    'Date Joined',\n",
        "    'Staff Bank Affiliations',\n",
        "    'Primary Staff Banks',\n",
        "    'Job Listing ID',\n",
        "    'Job Listing Title',\n",
        "    'Listing Site',\n",
        "    'Listing Organisation',\n",
        "    'Sub-specialty',\n",
        "    'Job Listing Published Date',\n",
        "    'Job Listing Published Time',\n",
        "    'Published',\n",
        "    'Application Deadline Date',\n",
        "    'Application Deadline Time',\n",
        "    'Start Time',\n",
        "    'End Time',\n",
        "    'Average Hourly Rate',\n",
        "    'Professional Flagged as Unavailable',\n",
        "    'Unavailability Reason',\n",
        "    'Last actioned by',\n",
        "    'Accounting Status',\n",
        "    'Candidate Tags'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "iZ-6Zl_ZGiaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'Profession',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Cost Centre',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Start Date',\n",
        "    'Total Hours',\n",
        "    'Grade Applied for',\n",
        "    'Calculated Pay (Indicative)',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder the columns\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6F3Xa8pAHHxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Bank_A&C_Dom_Estates_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "itoSemkyHR_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bank AHP**"
      ],
      "metadata": {
        "id": "kJTP21uPHt8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file containing the LN Bank data and display the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('Bank_AHP.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "WOA7S7Q2Hfac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with the word \"Bank\" in every row\n",
        "df['Bank/agency'] = 'Bank'\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Im7l079UHh3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Application ID',\n",
        "    'Professional registration number',\n",
        "    'Application Date',\n",
        "    'Application Time',\n",
        "    'Current Application Status',\n",
        "    'Current Application status effective date',\n",
        "    'Current Application status effective time',\n",
        "    'Reason for Cancellation',\n",
        "    'Reason for Rejection',\n",
        "    'Reason for Rejection Description',\n",
        "    'Applicant Staff Bank Status',\n",
        "    'Date Joined',\n",
        "    'Staff Bank Affiliations',\n",
        "    'Primary Staff Banks',\n",
        "    'Job Listing ID',\n",
        "    'Job Listing Title',\n",
        "    'Listing Site',\n",
        "    'Listing Organisation',\n",
        "    'Sub-specialty',\n",
        "    'Job Listing Published Date',\n",
        "    'Job Listing Published Time',\n",
        "    'Published',\n",
        "    'Application Deadline Date',\n",
        "    'Application Deadline Time',\n",
        "    'Start Time',\n",
        "    'End Time',\n",
        "    'Average Hourly Rate',\n",
        "    'Professional Flagged as Unavailable',\n",
        "    'Unavailability Reason',\n",
        "    'Last actioned by',\n",
        "    'Accounting Status',\n",
        "    'Candidate Tags'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "cFxust3CHkfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'Profession',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Cost Centre',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Start Date',\n",
        "    'Total Hours',\n",
        "    'Grade Applied for',\n",
        "    'Calculated Pay (Indicative)',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder the columns\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "EV23SFOFHm2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Bank_AHP_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "UYrAwwD3HoLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bank Medics**"
      ],
      "metadata": {
        "id": "NhIoojLrH3in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file containing the LN Bank data and display the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('Bank_Medics.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "TJyzMKeDH6WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with the word \"Bank\" in every row\n",
        "df['Bank/agency'] = 'Bank'\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "0cxG1swLH9rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Application ID',\n",
        "    'Professional registration number',\n",
        "    'Application Date',\n",
        "    'Application Time',\n",
        "    'Current Application Status',\n",
        "    'Current Application status effective date',\n",
        "    'Current Application status effective time',\n",
        "    'Reason for Cancellation',\n",
        "    'Reason for Rejection',\n",
        "    'Reason for Rejection Description',\n",
        "    'Applicant Staff Bank Status',\n",
        "    'Date Joined',\n",
        "    'Staff Bank Affiliations',\n",
        "    'Primary Staff Banks',\n",
        "    'Job Listing ID',\n",
        "    'Job Listing Title',\n",
        "    'Listing Site',\n",
        "    'Listing Organisation',\n",
        "    'Sub-specialty',\n",
        "    'Job Listing Published Date',\n",
        "    'Job Listing Published Time',\n",
        "    'Published',\n",
        "    'Application Deadline Date',\n",
        "    'Application Deadline Time',\n",
        "    'Start Time',\n",
        "    'End Time',\n",
        "    'Average Hourly Rate',\n",
        "    'Professional Flagged as Unavailable',\n",
        "    'Unavailability Reason',\n",
        "    'Last actioned by',\n",
        "    'Accounting Status',\n",
        "    'Candidate Tags'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Y5k1EyCRH_By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'Profession',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Cost Centre',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Start Date',\n",
        "    'Total Hours',\n",
        "    'Grade Applied for',\n",
        "    'Calculated Pay (Indicative)',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder the columns\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2XEV-LIeIB95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Bank_Medics_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "JKUqBBeqIDNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bank RN & HCA**"
      ],
      "metadata": {
        "id": "yTd2G8rRIHBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file containing the LN Bank data and display the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('Bank_RN_HCA.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Sm7VYg-CIJw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column with the word \"Bank\" in every row\n",
        "df['Bank/agency'] = 'Bank'\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "A4RqVeREIM8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Application ID',\n",
        "    'Professional registration number',\n",
        "    'Application Date',\n",
        "    'Application Time',\n",
        "    'Current Application Status',\n",
        "    'Current Application status effective date',\n",
        "    'Current Application status effective time',\n",
        "    'Reason for Cancellation',\n",
        "    'Reason for Rejection',\n",
        "    'Reason for Rejection Description',\n",
        "    'Applicant Staff Bank Status',\n",
        "    'Date Joined',\n",
        "    'Staff Bank Affiliations',\n",
        "    'Primary Staff Banks',\n",
        "    'Job Listing ID',\n",
        "    'Job Listing Title',\n",
        "    'Listing Site',\n",
        "    'Listing Organisation',\n",
        "    'Sub-specialty',\n",
        "    'Job Listing Published Date',\n",
        "    'Job Listing Published Time',\n",
        "    'Published',\n",
        "    'Application Deadline Date',\n",
        "    'Application Deadline Time',\n",
        "    'Start Time',\n",
        "    'End Time',\n",
        "    'Average Hourly Rate',\n",
        "    'Professional Flagged as Unavailable',\n",
        "    'Unavailability Reason',\n",
        "    'Last actioned by',\n",
        "    'Accounting Status',\n",
        "    'Candidate Tags'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "CaeBZTLSIQOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'Profession',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Cost Centre',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Start Date',\n",
        "    'Total Hours',\n",
        "    'Grade Applied for',\n",
        "    'Calculated Pay (Indicative)',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder the columns\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "eXM3id7VIe79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Bank_RNA_HCA_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "z3PHQc2BIgaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PlusUs- Bank & Agency**"
      ],
      "metadata": {
        "id": "_LT-lZvaIpKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the excel file containing the PlusUs data and display the first 5 rows to verify successful loading\n",
        "df = pd.read_excel('PlusUs_Bank_Agency.xlsx')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iFom9YiCIxXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to keep only rows where 'TS Status' is 'Confirmed'\n",
        "df = df[df['TS Status'].str.lower() == 'confirmed']"
      ],
      "metadata": {
        "id": "QETzcwD-Mkyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill blank values in 'NHSi Grade' with the last 6 characters from 'GradeName'\n",
        "\n",
        "# Convert empty strings to NaN first\n",
        "df['NHSi Grade'].replace('', pd.NA, inplace=True)\n",
        "\n",
        "# Fill NaN with last 6 chars of GradeName\n",
        "df['NHSi Grade'] = df['NHSi Grade'].fillna(df['GradeName'].str[-6:])"
      ],
      "metadata": {
        "id": "4tGmFW-IPtE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 'Bank/agency' column based on the value in 'AgencyName'\n",
        "df['Bank/agency'] = df['Agencyname'].apply(\n",
        "    lambda x: 'Bank' if x == \"Ashford and St Peters NHS Trust's Bank Agency\" else 'Agency'\n",
        ")"
      ],
      "metadata": {
        "id": "56q_-k0lQnQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'VacanciesRef', 'Client', 'ClientSiteName', 'Division', 'VacancyStatus', 'ShiftRef', 'ShiftStatus',\n",
        "    'Shift To Date', 'Shift From Time', 'Shift To Time', 'GradeName', 'AssignmentRef', 'LocumRef',\n",
        "    'Contract Type', 'PaymentMethod', 'Assignment Status', 'Agencyname', 'TotalChargePerHour',\n",
        "    'WorkerChargePerHour', 'TotalOutOfHoursCharge', 'WorkerOutOfHoursCharge', 'TsFromDate', 'TsToDate',\n",
        "    'TsFromTime', 'TsToTime', 'Breaks', 'HasBeenInvoiced', 'TS Status', 'LastStatusChangedBy',\n",
        "    'LastStatusChangedOn', 'InvoiceNumber', 'Invoice Status', 'Invoice Date', 'TotalPaidHours',\n",
        "    'WorkertotalCharge', 'AgencyTotalCharge', 'ChargeC', 'PayC', 'UChargeC', 'UPayC', 'Charge Capped',\n",
        "    'Wage Capped', 'CR Result', 'UCharge Capped', 'UWage Capped', 'UCR Result', 'Capped Cat',\n",
        "    'UnCapped Cat', 'Timesheet Estimated Cost', 'Worker Estimated Cost', 'Agency Estimated Cost',\n",
        "    'Bill%', 'Brookson Fee', 'AmendedFrom', 'AmendedTo', 'NumberOfCandidates', 'VacancyCreatedByEmail',\n",
        "    'Assignment Shift Status', 'Discipline', 'NHSi Staff Group', 'Requested Date', '2017-07-24',\n",
        "    'ISNHSIGrade', 'UnsociableMinutes', 'UnsociableHours', 'SociableMinutes', 'SociableHours',\n",
        "    'Core Count', 'US Count', 'Day', 'Bill Charge (Â£ p/h)', 'Week Commencing', 'Week Ending',\n",
        "    'Total Savings', 'Missed Savings', 'ShiftBreaching', 'NHSiImpact-Core', 'NHSiImpact-US',\n",
        "    'NHSiImpactTotal', 'NHSiDiff'\n",
        "]\n",
        "\n",
        "# Drop those columns\n",
        "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "D_EKMQJRT2l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning - staff group\n",
        "\n",
        "df['Subdisciplinename'] = df['Subdisciplinename'].replace('Doctor  No approval needed', 'Medic')\n",
        "df['Subdisciplinename'] = df['Subdisciplinename'].replace('AdminClerical', 'Admin and Clerical')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "WkNbpT93lDiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "desired_order = [\n",
        "    'DepartmentsName',\n",
        "    'CostCentre',\n",
        "    'Shift From Date',\n",
        "    'Subdisciplinename',\n",
        "    'BookedTotalHours',\n",
        "    'VacancyReason',\n",
        "    'FirstName',\n",
        "    'LastName',\n",
        "    'TotalCost',\n",
        "    'NHSi Grade',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder columns, only keeping those that exist in the DataFrame\n",
        "df = df[[col for col in desired_order if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "3Xeb9PV9UNXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('PlusUs_cleaned.xlsx', index=False)"
      ],
      "metadata": {
        "id": "huH3LDGDUaJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collation - Merging cleaned files**"
      ],
      "metadata": {
        "id": "rzKl8imCVqP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Column Mapping Dictionaries**"
      ],
      "metadata": {
        "id": "6vYkqQFjb3MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping for Agency files\n",
        "agency_map = {\n",
        "    'Profession': 'Profession',\n",
        "    'First Name': 'First Name',\n",
        "    'Last Name': 'Last Name',\n",
        "    'Cost Centre': 'Cost Centre',\n",
        "    'Department': 'Department',\n",
        "    'Vacancy Reason': 'Vacancy Reason',\n",
        "    'Start Date': 'Start Date',\n",
        "    'Total hours': 'Total Hours',\n",
        "    'Grade': 'Grade Applied for',\n",
        "    'Total Pay including agency fees excluding break time deduction (Â£)': 'Calculated Pay (Indicative)',\n",
        "    'Bank/agency': 'Bank/agency'\n",
        "}\n",
        "\n",
        "# Mapping for Bank files\n",
        "bank_map = {\n",
        "    'Profession': 'Profession',\n",
        "    'First Name': 'First Name',\n",
        "    'Last Name': 'Last Name',\n",
        "    'Cost Centre': 'Cost Centre',\n",
        "    'Department': 'Department',\n",
        "    'Vacancy Reason': 'Vacancy Reason',\n",
        "    'Start Date': 'Start Date',\n",
        "    'Total Hours': 'Total Hours',\n",
        "    'Grade Applied for': 'Grade Applied for',\n",
        "    'Calculated Pay (Indicative)': 'Calculated Pay (Indicative)',\n",
        "    'Bank/agency': 'Bank/agency'\n",
        "}\n",
        "\n",
        "# Mapping for PlusUs\n",
        "plusus_map = {\n",
        "    'Subdisciplinename': 'Profession',\n",
        "    'FirstName': 'First Name',\n",
        "    'LastName': 'Last Name',\n",
        "    'CostCentre': 'Cost Centre',\n",
        "    'DepartmentsName': 'Department',\n",
        "    'VacancyReason': 'Vacancy Reason',\n",
        "    'Shift From Date': 'Start Date',\n",
        "    'BookedTotalHours': 'Total Hours',\n",
        "    'NHSi Grade': 'Grade Applied for',\n",
        "    'TotalCost': 'Calculated Pay (Indicative)',\n",
        "    'Bank/agency': 'Bank/agency'\n",
        "}"
      ],
      "metadata": {
        "id": "GGuVojfwVvaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and Standardise cleaned files**"
      ],
      "metadata": {
        "id": "oJr_vef6NVrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function to load and standardise\n",
        "def load_and_standardize(filepath, col_map):\n",
        "    df = pd.read_excel(filepath)\n",
        "    df = df.rename(columns=col_map)\n",
        "    return df"
      ],
      "metadata": {
        "id": "wCubESrUNb-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load cleaned agency file\n",
        "agency_df = load_and_standardize(\"Agency_RN_HCA_cleaned.xlsx\", agency_map)\n",
        "\n",
        "# Load cleaned bank files\n",
        "bank_files = [\n",
        "    \"Bank_A&C_Dom_Estates_cleaned.xlsx\",\n",
        "    \"Bank_AHP_cleaned.xlsx\",\n",
        "    \"Bank_Medics_cleaned.xlsx\",\n",
        "    \"Bank_RNA_HCA_cleaned.xlsx\"\n",
        "]\n",
        "\n",
        "bank_dfs = [load_and_standardize(file, bank_map) for file in bank_files]\n",
        "\n",
        "# Load cleaned PlusUs file\n",
        "plusus_df = load_and_standardize(\"PlusUs_cleaned.xlsx\", plusus_map)"
      ],
      "metadata": {
        "id": "iDk3o27aNdmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine files**"
      ],
      "metadata": {
        "id": "X0WSQF28OGip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([agency_df] + bank_dfs + [plusus_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "pLkRxHzJOMQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cost Centre Corrections**"
      ],
      "metadata": {
        "id": "-86z2aA-kssV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove whitespace from cost centre and department\n",
        "df['Cost Centre'] = df['Cost Centre'].astype(str).str.strip()\n",
        "df['Department'] = df['Department'].astype(str).str.strip()\n",
        "\n",
        "# ITU\n",
        "mask_itu = (df['Cost Centre'] == '900039') & (df['Department'] == 'Intensive Therapy Unit')\n",
        "df.loc[mask_itu, 'Cost Centre'] = '900362'\n",
        "\n",
        "# Urology\n",
        "mask_urology = (df['Cost Centre'] == '900039') & (df['Department'] == 'Urology')\n",
        "df.loc[mask_urology, 'Cost Centre'] = '900691'"
      ],
      "metadata": {
        "id": "oPKw3kOVkvVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create and Lookup Staff Group**"
      ],
      "metadata": {
        "id": "mOhd2qmMPSc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the lookup table for profession and staff group\n",
        "table6 = pd.read_csv(\"table6.csv\")\n",
        "\n",
        "# Ensure both columns are strings, stripped of whitespace\n",
        "df['Profession'] = df['Profession'].astype(str).str.strip()\n",
        "table6['Profession'] = table6['Profession'].astype(str).str.strip()\n",
        "\n",
        "# Merge it with data on the Profession column\n",
        "df = df.merge(table6, on=\"Profession\", how=\"left\")"
      ],
      "metadata": {
        "id": "-cm-c3dcPZFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add Name column**"
      ],
      "metadata": {
        "id": "hB6DFLSPQZnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCAT First Name + Last Name\n",
        "df['Name'] = df['First Name'].str.strip() + ' ' + df['Last Name'].str.strip()"
      ],
      "metadata": {
        "id": "BR2e0muiQY-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create and Lookup Division & Specialty**"
      ],
      "metadata": {
        "id": "spw1RBzaQu3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the lookup table for cost centre and division\n",
        "table1 = pd.read_csv(\"table1.csv\")\n",
        "\n",
        "# Ensure both columns are strings, stripped of whitespace\n",
        "df['Cost Centre'] = df['Cost Centre'].astype(str).str.strip()\n",
        "table1['Cost Centre'] = table1['Cost Centre'].astype(str).str.strip()\n",
        "\n",
        "# Merge the lookup table into df on cost centre\n",
        "df = df.merge(table1[['Cost Centre', 'Division - Mapped', 'Specialty - Mapped']], on='Cost Centre', how='left')"
      ],
      "metadata": {
        "id": "wWF7K7tbQws4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace Blank Vacancy reason rows with Unknown**"
      ],
      "metadata": {
        "id": "xiYCIEx7R3Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace blanks in 'Vacancy Reason' with 'Unknown'\n",
        "df['Vacancy Reason'] = df['Vacancy Reason'].fillna('')\n",
        "df.loc[df['Vacancy Reason'].str.strip() == '', 'Vacancy Reason'] = 'Unknown'"
      ],
      "metadata": {
        "id": "j_OzO_7jR8TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create and Lookup Vacancy Reason-Mapped**\n",
        "\n"
      ],
      "metadata": {
        "id": "x86ryba3SHgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the lookup table for vacancy reason\n",
        "table8 = pd.read_csv(\"table8.csv\")\n",
        "\n",
        "# Ensure both columns are strings, stripped of whitespace\n",
        "df['Vacancy Reason'] = df['Vacancy Reason'].astype(str).str.strip()\n",
        "table8['Vacancy Reason'] = table8['Vacancy Reason'].astype(str).str.strip()\n",
        "\n",
        "# Merge it with data on the Vacancy Reason column\n",
        "df = df.merge(table8, on=\"Vacancy Reason\", how=\"left\")"
      ],
      "metadata": {
        "id": "WggVC8hkSMfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create and Lookup Grade-Mapped**\n",
        "\n"
      ],
      "metadata": {
        "id": "tqUsm-ltg7CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the lookup table for grade\n",
        "table10 = pd.read_csv(\"table10.csv\")\n",
        "\n",
        "# Ensure both columns are strings, stripped of whitespace\n",
        "df['Grade Applied for'] = df['Grade Applied for'].astype(str).str.strip()\n",
        "table10['Grade Applied for'] = table10['Grade Applied for'].astype(str).str.strip()\n",
        "\n",
        "# Merge it with data on the Grade Applied for column\n",
        "df = df.merge(table10, on=\"Grade Applied for\", how=\"left\")"
      ],
      "metadata": {
        "id": "YeCHKJpQhAO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete >30 Hours**"
      ],
      "metadata": {
        "id": "OWCQC3TGSnKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['Total Hours'] <= 30]"
      ],
      "metadata": {
        "id": "GPZxIytUSqtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculated Columns**"
      ],
      "metadata": {
        "id": "3vVavEfNkD3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Daily & weekly fractions\n",
        "df['Daily Fraction'] = df['Total Hours'] / 7.5\n",
        "df['Weekly Fraction'] = df['Total Hours'] / 37.5\n",
        "\n",
        "# Hourly rate\n",
        "df['Hourly Rate'] = df['Calculated Pay (Indicative)'] / df['Total Hours']"
      ],
      "metadata": {
        "id": "xfuEiXmXkHHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete Calculated Pay = 0**"
      ],
      "metadata": {
        "id": "Huy3oi9ehfOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"Calculated Pay (Indicative)\"] != 0]"
      ],
      "metadata": {
        "id": "X4ofTSoehmld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove data older than 6 months**"
      ],
      "metadata": {
        "id": "wz5e6zwio8D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Start Date is in datetime format\n",
        "df['Start Date'] = pd.to_datetime(df['Start Date'], errors='coerce')\n",
        "\n",
        "# Get the first day of the current month\n",
        "today = pd.Timestamp.today()\n",
        "first_of_this_month = pd.Timestamp(today.year, today.month, 1)\n",
        "\n",
        "# Go back 6 months\n",
        "cutoff_date = first_of_this_month - DateOffset(months=6)\n",
        "\n",
        "# Filter your DataFrame\n",
        "df = df[df['Start Date'] >= cutoff_date]"
      ],
      "metadata": {
        "id": "PX-2te7RpAF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Re-order Columns**"
      ],
      "metadata": {
        "id": "ITwjDa0p-7tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired column order\n",
        "column_order_collated = [\n",
        "    'Profession',\n",
        "    'Staff Group - Mapped',\n",
        "    'First Name',\n",
        "    'Last Name',\n",
        "    'Name',\n",
        "    'Cost Centre',\n",
        "    'Division - Mapped',\n",
        "    'Specialty - Mapped',\n",
        "    'Department',\n",
        "    'Vacancy Reason',\n",
        "    'Vacancy Reason - Mapped',\n",
        "    'Start Date',\n",
        "    'Total Hours',\n",
        "    'Daily Fraction',\n",
        "    'Weekly Fraction',\n",
        "    'Grade Applied for',\n",
        "    'Grade - Mapped',\n",
        "    'Calculated Pay (Indicative)',\n",
        "    'Hourly Rate',\n",
        "    'Bank/agency'\n",
        "]\n",
        "\n",
        "# Reorder columns, only keeping those that exist in the DataFrame\n",
        "df = df[[col for col in column_order_collated if col in df.columns]]\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "QtgFf0kE_AJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Collated and Cleaned file**"
      ],
      "metadata": {
        "id": "ZG5hRox6lnQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DataFrame to Excel\n",
        "df.to_excel('Collated.xlsx', index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download('Collated.xlsx')"
      ],
      "metadata": {
        "id": "-A6n5u0Nlsss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}